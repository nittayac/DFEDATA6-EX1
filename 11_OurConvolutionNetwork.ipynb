{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11 OurConvolutionNetwork.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nittayac/DFEDATA6-EX1/blob/main/11_OurConvolutionNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVn_dUcN-MPL",
        "outputId": "11d6ac7a-87dc-4358-c24d-66f1e1b79634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# NEURAL NETWORKS DO NOT DO DATA CLEANING!\n",
        "\n",
        "# IF TF prefers channels _Last-> we need to arrange our images before passing to NN\n",
        "# THEANO -> Channels_first -> WE need to arrange our images\n",
        "\n",
        "\n",
        "# in our NLP problem -> preprocessed sentences were analyzed\n",
        "# in our CV problems-> images are preprocessed \n",
        "!ls\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgQWq65r_Hgv",
        "outputId": "2a2a4759-eab3-4349-9f54-49ac926e1df5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "img = cv2.imread('000003.jpg')\n",
        "img_resized = cv2.resize(img, (200,200)) # SMALL DISTORTION are WELCOME! \n",
        "cv2_imshow(img_resized)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=200x200 at 0x7F95509F30F0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_UrZDhr_-76",
        "outputId": "870bd99d-288d-43d8-9cce-443cf46f907d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "img_resized[0] # EACH element is a LIST of 3 elements -> CHANNEL value-> 3 channels\n",
        "img_resized.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 200, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkTTK6ZOAR1Q",
        "outputId": "13cd3e31-dc3f-4516-de86-18f2cc82c392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "img_resized[5][0] # 5th row, 0th column\n",
        "\n",
        "# uint8 -> each channel is unsigned (no negative signs) and 8 bit in size "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([255, 255, 255], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q0GHkfNA8MR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b4c631f-0a83-4c57-9c30-2f08295a9735"
      },
      "source": [
        "import numpy as np\n",
        "from keras import backend # backend -> tf/theano etc\n",
        "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Sequential # no parallel, no cycles \n",
        "\n",
        "# TF can create all = DAG, DCG, IAG, ICG "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BVCnCrFTxM5"
      },
      "source": [
        "# SUCH networks can be VERY large and usually only 1 instance runs \n",
        "# otherwise RAM will be cluttered and all will crash! (OS+model+harddisk)\n",
        "\n",
        "# NO MORE THAN 1 INSTANCE of such programs should be RUNNING! \n",
        "\n",
        "# SINGLETON -> class which can have ONLY 1 instance -> TASK MANAGER! "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz1VGDNmV65s"
      },
      "source": [
        "\n",
        " # the method declared after @st... will be STATIC\n",
        "  # ONLY 1 copy of it will RUN from the beginning till the end of program\n",
        "  # STATIC keyword -> STATIC MEANS ALWAYS PRESENT (Static CURRENT!)\n",
        "\n",
        "  # DEPTH = Channel depth = channel dimension = no. of channels \n",
        "  #                       \n",
        "# KERAS needs us to arrange -> IMAGE STRUCTURE \n",
        "    # Tensorflow -> CHANNEL_LAST -> (height, width, depth)\n",
        "    # Theano -> CHANNEL_FIRST -> (depth, height, width)\n",
        "    # https://machinelearningmastery.com/a-gentle-introduction-to-channels-first-and-channels-last-image-formats-for-deep-learning/\n",
        "\n",
        "\n",
        "# PandaVGG = ((Conv + ReLU + BN) + MP + Dropout + ( (Conv + ReLU + BN) + MP + Dropout)XN\n",
        "#             + (Flatten + Dense(ReLu) + Dense(SoftMax))\n",
        "\n",
        "class PandaVGG:\n",
        "  @staticmethod\n",
        "  def build( height, width, depth, classes) :\n",
        "  \n",
        "    # let's assume we are on TF, else we will switch to Theano \n",
        "    inputShape = (height, width, depth)\n",
        "    channel_dim = -1  # last element -> CHANNELS_LAST \n",
        "    if backend.image_data_format() == 'channels_first':\n",
        "      inputShape = (depth, height, width)\n",
        "      channel_dim = 1\n",
        "    # { data, representation } => [data,representation] or [representation, data]\n",
        "    #  { images, channels}     => channels_last or channels_first \n",
        "    # data -> 2 d images -> height [row], width [columns] \n",
        "\n",
        "    HP_block1_conv_dim = 32    \n",
        "    HP_small_pattern = (3,3)\n",
        "    HP_block2_conv_dim = 64\n",
        "    HP_block3_conv_dim = 128\n",
        "    HP_block4_conv_dim = 256\n",
        "    HP_block5_dense_dim = 1024\n",
        "    HP_large_pattern = (2,2)\n",
        "    HP_dropout_type1 = 0.25\n",
        "    HP_dropout_type2 = 0.50\n",
        "    \n",
        "    model = Sequential()\n",
        "# PandaVGG = (Conv + ReLU + BN) + MP + Dropout + ((Conv + ReLU + BN)X2 + MP + Dropout) X N\n",
        "#             + (Flatten + Dense(ReLu) + Dense(SoftMax))\n",
        "\n",
        "    # block1 starts-> (Conv + ReLU + BN) + MP + Dropout \n",
        "    model.add(Conv2D(HP_block1_conv_dim, HP_small_pattern, padding='same', input_shape=inputShape))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim)) # our data needs to be normalized, not our channels!!!\n",
        "    model.add(MaxPooling2D(pool_size=HP_small_pattern))\n",
        "    model.add(Dropout(HP_dropout_type1))\n",
        "    # block1 complete \n",
        "\n",
        "    #block2 starts -> (Conv + RelU + BN) X2   + Compress + Drop \n",
        "    model.add(Conv2D(HP_block2_conv_dim,HP_small_pattern, padding='same' ))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(Conv2D(HP_block2_conv_dim,HP_small_pattern, padding='same' ))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(MaxPooling2D(pool_size=HP_large_pattern))\n",
        "    model.add(Dropout(HP_dropout_type1))\n",
        "    # BLock 2 ends \n",
        "\n",
        "    #Block3 starts\n",
        "    model.add(Conv2D(HP_block3_conv_dim,HP_small_pattern, padding='same' ))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(Conv2D(HP_block3_conv_dim,HP_small_pattern, padding='same' ))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(MaxPooling2D(pool_size=HP_large_pattern))\n",
        "    model.add(Dropout(HP_dropout_type1))\n",
        "    # block3 ends\n",
        "\n",
        "    #Block4 starts\n",
        "    model.add(Conv2D(HP_block4_conv_dim,HP_small_pattern, padding='same' ))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(Conv2D(HP_block4_conv_dim,HP_small_pattern, padding='same' ))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=channel_dim))\n",
        "    model.add(MaxPooling2D(pool_size=HP_large_pattern))\n",
        "    model.add(Dropout(HP_dropout_type1))\n",
        "    # block4 ends\n",
        "\n",
        "    # final block5- classification/prediction\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(HP_block5_dense_dim))\n",
        "    model.add(Activation('relu'))\n",
        "    # optional: Batch Normalization and Dropout -> to avoid overfitting \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(HP_dropout_type2))\n",
        "    model.add(Dense(classes))\n",
        "    model.add(Activation('softmax'))\n",
        "    # final block ends\n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsqHr2JaObEn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f252072e-3ea1-4fb0-f057-9fa03dfb6daf"
      },
      "source": [
        " # minimum image sizes that NN can clearly identify\n",
        "# black & white images                          -> 28X28 \n",
        "# multi-channels images (3 channels in our case)-> 96X96 (3 X (32,32)) \n",
        "\n",
        "model = PandaVGG.build(96, 96, 3, 3)\n",
        "model.summary() \n",
        "\n",
        "# 32 filters -> each filter is 3X3 -> PER CHANNEL\n",
        "# 1 filter = [ [w11,w12,w13],[w21,w22,w23],[w31,w32,w33]] -> 9 weights \n",
        "# 32 X 9 = 288 -> 1 channel\n",
        "\n",
        "# 288 X 3 = 864 weights\n",
        "# 32 filters generated, each with 1 bias\n",
        "# weights + bias = 864 + 32 = 896\n",
        "\n",
        "# EXPORT the built model -> right approach \n",
        "# next file-> train.py -> import the model "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 96, 96, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 96, 96, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 96, 96, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 3075      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 5,369,219\n",
            "Trainable params: 5,365,315\n",
            "Non-trainable params: 3,904\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmLr0E8mU9Pa"
      },
      "source": [
        "# data_clean.py \n",
        "# in real life, should have been a separate file\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "from sklearn.preprocessing import LabelBinarizer # Label encoding, 1-hot encoding, multi-encoding\n",
        "# LABEL binarizer is a 1-hot encoded MATRIX \n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import imutils\n",
        "from imutils import paths\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx3uMIvDVQZc"
      },
      "source": [
        "# if this was a User Facing software or web/mobile app, we would have been using a UI\n",
        "HP_dataset = 'data'\n",
        "HP_model_path = 'bin/model'\n",
        "HP_binarized_labels = 'bin/labels'\n",
        "HP_metrics_storage = 'eval'\n",
        "HP_test_dataset = 'test'\n",
        "HP_epoch = 100\n",
        "HP_init_lr = 1e-3 # learning_rate = 0.001\n",
        "HP_batch_size = 32\n",
        "HP_image_dim = (96,96,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00xIhEifYo26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "7b1ecbed-bb98-4aaf-8810-0f0d6cd6c017"
      },
      "source": [
        "data = []\n",
        "labels = [] \n",
        "# read all images\n",
        "all_images = sorted(list(paths.list_images(HP_dataset)))\n",
        "all_images[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/dogs/00001.png',\n",
              " 'data/dogs/00005.png',\n",
              " 'data/dogs/00087.png',\n",
              " 'data/dogs/00120.png',\n",
              " 'data/dogs/00132.png']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNwYb47uZoVe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "6a2bcf3d-241a-41a7-e30a-a6437a8a8f12"
      },
      "source": [
        "random.seed(42)\n",
        "random.shuffle(all_images)\n",
        "all_images[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/pikachu/00000015.jpg',\n",
              " 'data/shaktiman/Shaktiman 00000071.jpg',\n",
              " 'data/shaktiman/Shaktiman 00000148.jpg',\n",
              " 'data/pikachu/00000134.png',\n",
              " 'data/pikachu/00000067.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg-WQMLhaAQg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bd77cbcb-279e-4d17-c2eb-32ad7294f095"
      },
      "source": [
        "import os\n",
        "for impath in all_images:\n",
        "  img = cv2.imread(impath)\n",
        "  resized = cv2.resize(img, (HP_image_dim[0],HP_image_dim[1]) )\n",
        "  imageData = img_to_array(resized)\n",
        "  data.append(imageData)\n",
        "  # extract label from filename (2nd last element) / \\\\ \n",
        "  label = impath.split(os.path.sep)[-2]\n",
        "  labels.append(label)\n",
        "\n",
        "print(labels[0])\n",
        "#print(data[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pikachu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPg_LAalTxHF"
      },
      "source": [
        " # BATCH NORMALIZATION FUN FACT \n",
        "    # we will be calculating -> mu and sigma for normalization \n",
        "    # parameters will be generated\n",
        "    # but in back/prop-> IS my data(images) changing? if my data is not changing\n",
        "    # then mu and sigma for that data/batch will not change!!! \n",
        "    # Non-TRAINABLE parameters -> that cannot be trained -> back-prop's differentiation \n",
        "    # will NOT change their value! "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26PFtAS1qvMd"
      },
      "source": [
        "# https://1drv.ms/u/s!AhM-uOEWdqAeqG9rJT9XKZp62sCj?e=hl5sKg\n",
        "# https://1drv.ms/u/s!AhM-uOEWdqAexWFgIl-sNiHnq0JM?e=V3cG4m\n",
        "\n",
        "# Pattern Recognition: pattern recognition by Sergios Theodoridis, Konstantinos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU4d4M3LqiqM"
      },
      "source": [
        "# CONVOLUTIONAL neural networks + Recurring Networks + Lot of unknown stuff = Brain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvpPcQJpjFTl"
      },
      "source": [
        "# Color theory: https://www.springer.com/gp/book/9780792399285\n",
        "\n",
        "# Concious / Unconcious -> myth \n",
        "# Cerebrum, Cerebellum, Corpus callosum, medulla -> Biologist \n",
        "# biologist and neurologist -> CLASSFIED brains into activities\n",
        "# \n",
        "# They are now proven to be partial knowledges!\n",
        "\n",
        "# Optical nerve was working fine but postoral lobe responsible for\n",
        "# vision was damaged \n",
        "\n",
        "# Neurosurgeons -> clipped optical nerve and connected to a different segment of brain\n",
        "# within matter of months, BRAIN taught itself to SEE from the area where it was not supposed\n",
        "# to! \n",
        "\n",
        "# BRAIN -> Weights and BIASES and unknown parameters! "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uwp0Bu5Iqfmg",
        "outputId": "a909a243-fd54-4c5a-9c8e-919b41bfc10a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "model = VGG16()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 6s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltNfJ6RKrOZ6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}