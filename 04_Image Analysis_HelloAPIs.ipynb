{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HelloAPIs.ipynb",
      "provenance": [],
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nittayac/DFEDATA6-EX1/blob/main/04_Image%20Analysis_HelloAPIs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1s_MwEw3GRV",
        "outputId": "7820c548-fa27-42bc-8b75-556462b5af92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure-cognitiveservices-vision-computervision\n",
            "  Downloading azure_cognitiveservices_vision_computervision-0.9.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting azure-common~=1.1\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Collecting msrest>=0.5.0\n",
            "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.3.1)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 510 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests~=2.16 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.2.0)\n",
            "Installing collected packages: isodate, msrest, azure-common, azure-cognitiveservices-vision-computervision\n",
            "Successfully installed azure-cognitiveservices-vision-computervision-0.9.0 azure-common-1.1.28 isodate-0.6.1 msrest-0.6.21\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade azure-cognitiveservices-vision-computervision\n",
        "!pip install pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "from array import array\n",
        "import os\n",
        "from PIL import Image\n",
        "import sys\n",
        "import time"
      ],
      "metadata": {
        "id": "VTH6uQPF3N59"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#subscription_key = \"7db033dbbbc141e1af52f567e4c9cc36\"\n",
        "#endpoint = \"https://popopopopo.cognitiveservices.azure.com/\"\n",
        "\n",
        "\n",
        "subscription_key = \"59b0d8d0ba5647de95962d9f460fc9e6\"\n",
        "endpoint = \"https://imageanalysis2022.cognitiveservices.azure.com/\""
      ],
      "metadata": {
        "id": "jZNuM3tr3gh8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creds= CognitiveServicesCredentials(subscription_key)\n",
        "computervision_client = ComputerVisionClient(endpoint, creds)\n",
        "# API Authentication settings"
      ],
      "metadata": {
        "id": "R70IuGyQ4mus"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from posix import listdir\n",
        "#baseimgurl = 'https://dodokilledplatypus.blob.core.windows.net/images/0000'\n",
        "\n",
        "baseimgurl = 'https://images20222.blob.core.windows.net/images/000'\n",
        "\n",
        "\n",
        "allurls = []\n",
        "for i in range(3):\n",
        "  filename = baseimgurl + str(i+1) + '.jpg'\n",
        "  allurls.append(filename)\n",
        "\n",
        "allurls\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT3tDUFz4_c0",
        "outputId": "9b96bb5f-3d61-4d9a-f099-93eb7c8f11c0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://images20222.blob.core.windows.net/images/0001.jpg',\n",
              " 'https://images20222.blob.core.windows.net/images/0002.jpg',\n",
              " 'https://images20222.blob.core.windows.net/images/0003.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Describe an Image - remote\n",
        "This example describes the contents of an image with the confidence score.\n",
        "'''\n",
        "print(\"===== Describe an image - remote =====\")\n",
        "# Call API\n",
        "\n",
        "for url in allurls:\n",
        "  description_results =  computervision_client.describe_image(url)\n",
        "\n",
        "  print(\"Description of remote image: \")\n",
        "  if (len(description_results.captions) == 0):\n",
        "      print(\"No description detected.\")\n",
        "  else:\n",
        "      for caption in description_results.captions:\n",
        "          print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))\n",
        "  print('**************************')\n",
        "# Get the captions (descriptions) from the response, with confidence level\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kabQiDln6zEI",
        "outputId": "e8b61eee-6e19-4bfb-961e-a3ce2b9ff7fb"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Describe an image - remote =====\n",
            "Description of remote image: \n",
            "'a person in a suit and bow tie with Matt Smith et al. behind him' with confidence 50.23%\n",
            "**************************\n",
            "Description of remote image: \n",
            "'a group of toys' with confidence 38.06%\n",
            "**************************\n",
            "Description of remote image: \n",
            "'a house with a garage' with confidence 53.95%\n",
            "**************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Categorize an Image - remote\n",
        "This example extracts (general) categories from a remote image with a confidence score.\n",
        "'''\n",
        "print(\"===== Categorize an image - remote =====\")\n",
        "# Select the visual feature(s) you want.\n",
        "remote_image_features = [\"categories\"]\n",
        "# Call API with URL and features\n",
        "\n",
        "for url in allurls:\n",
        "  categorize_results_remote = computervision_client.analyze_image(url , remote_image_features)\n",
        "  # Print results with confidence score\n",
        "  print(\"Categories from remote image: \")\n",
        "  if (len(categorize_results_remote.categories) == 0):\n",
        "      print(\"No categories detected.\")\n",
        "  else:\n",
        "      for category in categorize_results_remote.categories:\n",
        "          print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))\n",
        "  print('**********')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jmTfUHD7T-9",
        "outputId": "d50d3f05-91b1-4f92-e4a2-405be97a3196"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Categorize an image - remote =====\n",
            "Categories from remote image: \n",
            "'people_group' with confidence 48.44%\n",
            "**********\n",
            "Categories from remote image: \n",
            "No categories detected.\n",
            "**********\n",
            "Categories from remote image: \n",
            "'building_' with confidence 66.80%\n",
            "'outdoor_house' with confidence 24.22%\n",
            "**********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Tag an Image - remote\n",
        "This example returns a tag (key word) for each thing in the image.\n",
        "'''\n",
        "print(\"===== Tag an image - remote =====\")\n",
        "# Call API with remote image\n",
        "for url in allurls:\n",
        "  tags_result_remote = computervision_client.tag_image(url )\n",
        "\n",
        "  # Print results with confidence score\n",
        "  print(\"Tags in the remote image: \")\n",
        "  if (len(tags_result_remote.tags) == 0):\n",
        "      print(\"No tags detected.\")\n",
        "  else:\n",
        "      for tag in tags_result_remote.tags:\n",
        "          print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))\n",
        "\n",
        "  print('*************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCifHuO97wE_",
        "outputId": "a4ddcb25-a0a6-42f9-b36c-279cfcf7b243"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Tag an image - remote =====\n",
            "Tags in the remote image: \n",
            "'human face' with confidence 99.61%\n",
            "'person' with confidence 99.55%\n",
            "'clothing' with confidence 99.28%\n",
            "'man' with confidence 92.46%\n",
            "'painting' with confidence 87.29%\n",
            "*************\n",
            "Tags in the remote image: \n",
            "'cartoon' with confidence 98.23%\n",
            "'animated cartoon' with confidence 93.99%\n",
            "'animation' with confidence 92.06%\n",
            "'tree' with confidence 90.55%\n",
            "*************\n",
            "Tags in the remote image: \n",
            "'building' with confidence 99.83%\n",
            "'outdoor' with confidence 99.41%\n",
            "'house' with confidence 99.21%\n",
            "'property' with confidence 99.16%\n",
            "'home' with confidence 98.59%\n",
            "'real estate' with confidence 98.27%\n",
            "'window' with confidence 97.07%\n",
            "'siding' with confidence 96.24%\n",
            "'sky' with confidence 96.01%\n",
            "'plant' with confidence 95.71%\n",
            "'grass' with confidence 94.48%\n",
            "'cottage' with confidence 92.74%\n",
            "'door' with confidence 92.59%\n",
            "'yard' with confidence 92.28%\n",
            "'roof' with confidence 91.84%\n",
            "'farmhouse' with confidence 91.11%\n",
            "'porch' with confidence 90.31%\n",
            "'driveway' with confidence 88.08%\n",
            "'garage door' with confidence 88.06%\n",
            "'garage' with confidence 84.95%\n",
            "'backyard' with confidence 84.63%\n",
            "'garden buildings' with confidence 84.50%\n",
            "'sash window' with confidence 84.41%\n",
            "'villa' with confidence 84.23%\n",
            "'architecture' with confidence 47.40%\n",
            "*************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Detect Faces - remote\n",
        "This example detects faces in a remote image, gets their gender and age, \n",
        "and marks them with a bounding box.\n",
        "'''\n",
        "\n",
        "\n",
        "print(\"===== Detect Faces - remote =====\")\n",
        "# Get an image with faces\n",
        "# Select the visual feature(s) you want.\n",
        "remote_image_features = [\"faces\"]\n",
        "# Call the API with remote URL and features\n",
        "\n",
        "for url in allurls:\n",
        "  detect_faces_results_remote = computervision_client.analyze_image(url, remote_image_features)\n",
        "\n",
        "  # Print the results with gender, age, and bounding box\n",
        "  print(\"Faces in the remote image: \")\n",
        "  if (len(detect_faces_results_remote.faces) == 0):\n",
        "      print(\"No faces detected.\")\n",
        "  else:\n",
        "      for face in detect_faces_results_remote.faces:\n",
        "          print(\"'{}' of age {} at location {}, {}, {}, {}\".format(face.gender, face.age, \\\n",
        "          face.face_rectangle.left, face.face_rectangle.top, \\\n",
        "          face.face_rectangle.left + face.face_rectangle.width, \\\n",
        "          face.face_rectangle.top + face.face_rectangle.height))\n",
        "  print('***********')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leqHPyx07-Rt",
        "outputId": "61c56667-f59b-43fa-eb01-19b337c6132c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Detect Faces - remote =====\n",
            "Faces in the remote image: \n",
            "'Male' of age 30 at location 182, 50, 251, 119\n",
            "'Male' of age 32 at location 270, 63, 322, 115\n",
            "***********\n",
            "Faces in the remote image: \n",
            "No faces detected.\n",
            "***********\n",
            "Faces in the remote image: \n",
            "No faces detected.\n",
            "***********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H6LcgheB9V2a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}